{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script to Clean up Lab Automation Data before Spotfire Import - \n",
    "\n",
    "Script 1 is for 1 single file (latest file)\n",
    "\n",
    "Script 2 is for all unprocessed files in the folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import glob\n",
    "import pathlib\n",
    "\n",
    "\n",
    "# * means all if need specific format then *.csv\n",
    "list_of_files = glob.glob('C:/Datafiles/AMC1300/*.txt') \n",
    "latest_file = max(list_of_files, key=os.path.getctime)\n",
    "print (latest_file)\n",
    "File_name=os.path.basename(latest_file)\n",
    "print(File_name)\n",
    "#Remove the .txt extension\n",
    "File_name = File_name[:-4]\n",
    "\n",
    "path = pathlib.Path('C:/Datafiles/AMC1300/Cleanedup/'+File_name+'.csv')\n",
    "re_search = re.search('..Temporary..', File_name)\n",
    "\n",
    "\n",
    " \n",
    "if (path.is_file() == False and re_search == None):\n",
    "#Read the file\n",
    "        print(\"Inside the IF\")\n",
    "        df = pd.read_csv(latest_file,sep='\\t',delimiter='\\t')\n",
    "        df=df.set_index('Meas_Name')\n",
    "        df=df.drop(['RunComment','STRING','TEST_ID'])\n",
    "        df=df.drop(['Sweep Version', 'Test Area','Package Type','Product Revision','Test_Parameter',\n",
    "            'Block ID','Channel','Test Type','Start time','Lot','Station Name','SCM',\n",
    "            'Upper Limit','Lower Limit','Nominal Value','End Time','Execution Duration (ms)',\n",
    "            'Loop Count','Run Mode Name','UserID','Comment'],axis=1)\n",
    "        df.to_csv('C:/Datafiles/AMC1300/Cleanedup/'+File_name+'.csv')\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script 2 - Removes trash columns from data log and inserts type row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file...AMC1300_14150468.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os , time\n",
    "import glob\n",
    "import pathlib\n",
    "import re\n",
    "list_of_files_raw_noext=[]\n",
    "#list_of_files_raw = glob.glob('C:/Datafiles/AMC1300/*.txt') \n",
    "No_of_files_processed=0\n",
    "No_of_files_skipped=0\n",
    "#PATH_FOR_CLEAN_DATALOG= 'C:/Datafiles/AMC1300/Cleanedup/'\n",
    "#PATH_FOR_RAW_DATALOG= 'C:/Datafiles/AMC1300/'\n",
    "\n",
    "#Get list of files in datalog folder\n",
    "list_of_files_raw = glob.glob('//Dtfr-ctpb1h43b/amc1300/*.txt')\n",
    "\n",
    "#initialize paths\n",
    "PATH_FOR_CLEAN_DATALOG= '//Dtfr-ctpb1h43b/amc1300/Cleanedup/'\n",
    "PATH_FOR_RAW_DATALOG= '//Dtfr-ctpb1h43b/amc1300/'\n",
    "##BASE_FILE_TIME = 1519948481.7437975\n",
    "\n",
    "\n",
    "#//Dtfr-ctpb1h43b/amc1300\n",
    "#AMC13XX (file://Dtfr-ctpb1h43b/amc13xx/)\n",
    "#Cleanedup (file://Dtfr-ctpb1h43b/amc13xx/Cleanedup)\n",
    "list_of_files_clean = glob.glob('//Dtfr-ctpb1h43b/amc1300/Cleanedup/*.csv') # * means all if need specific format then *.csv\n",
    "latest_file = max(list_of_files_clean, key=os.path.getctime)\n",
    "#print ('Latest clean file is ' + latest_file)\n",
    "BASE_FILE_TIME = os.path.getmtime(latest_file)\n",
    "\n",
    "for file in list_of_files_raw:\n",
    "    \n",
    "    re_search_bak = re.search('..bak', file) # search for .bak in filename\n",
    "    file_noext =os.path.basename(file[:-4]) #remove .ext from file name\n",
    "    list_of_files_raw_noext.append(file)\n",
    "    path = pathlib.Path(PATH_FOR_CLEAN_DATALOG+file_noext+'.csv')\n",
    "    \n",
    "    \n",
    "    re_search = re.search('..Temporary..', file_noext)\n",
    "    \n",
    "    if (path.is_file() == False and re_search==None and re_search_bak==None and os.path.getmtime(file)> BASE_FILE_TIME ):\n",
    "        \n",
    "        print(\"Processing file...\"+os.path.basename(file))\n",
    "        #print(\"last modified: %s\" % time.ctime(os.path.getmtime(file)))\n",
    "        #print(\"last modified: %s\" % os.path.getmtime(file))\n",
    "        #Read the file\n",
    "        df = pd.read_csv(PATH_FOR_RAW_DATALOG+file_noext+'.txt',sep='\\t',delimiter='\\t')\n",
    "        \n",
    "        #set Meas_Name as the DF index\n",
    "        #df=df.set_index('Device Descriptor')\n",
    "        df['index_col'] = df.index\n",
    "        #Rows to be removed (dropped), row 0 and 1\n",
    "        df=df.drop([0,1])\n",
    "      \n",
    "         #columns to be removed (dropped)\n",
    "\n",
    "        df=df.drop(['Sweep Version', 'Test Area','Package Type','Product Revision','Test_Parameter',\n",
    "            'Block ID','Channel','Test Type','Station Name','SCM',\n",
    "            'Upper Limit','Lower Limit','Nominal Value','End Time','Execution Duration (ms)',\n",
    "            'Loop Count','Run Mode Name','UserID','Comment'],axis=1)\n",
    "        #df = df.rename(columns={col: col.split('(')[0] for col in df.columns})\n",
    "        \n",
    "        \n",
    "        type_row=[]    \n",
    "        for column in df:\n",
    "            #print(column)\n",
    "            #print(df[column].unique())\n",
    "            #print('Column index is',df.columns.get_loc(column))\n",
    "            Column_idx=df.columns.get_loc(column)\n",
    "            for unique_val in df[column].unique():\n",
    "                if(pd.isnull(unique_val)==True):\n",
    "                #print(\"this element is NaN\")\n",
    "                  pass\n",
    "                else:\n",
    "                    try:\n",
    "                        float(unique_val)\n",
    "                        isnumber= True\n",
    "                        type_row.append(3.05) #just insert a real num in the first row so that spotfire detects it\n",
    "                        #print(column ,'is a Number')\n",
    "                        break \n",
    "                    except:\n",
    "                        Isnumber = False   \n",
    "                        type_row.append('STRING')\n",
    "                        #print( column,'is a String')\n",
    "                        break       \n",
    "        \n",
    "        try:\n",
    "            #Make a data frame with df.columns as index and type_row as column\n",
    "            df2 = pd.Series(type_row, index=[df.columns])\n",
    "            #append df2 transposed to df, gets type_as the last row\n",
    "            df2 = df.append(df2, ignore_index=True)\n",
    "            #swap last row(type row ) and first row\n",
    "            last_row, first_row = df2.iloc[-1].copy(), df2.iloc[0].copy()\n",
    "            df2.iloc[-1],df2.iloc[0] = first_row,last_row\n",
    "        \n",
    "            df2.to_csv(PATH_FOR_CLEAN_DATALOG+file_noext+'.csv')\n",
    "            \n",
    "        except:\n",
    "            print(\"Not a valid file \"+file_noext+'.txt')\n",
    "            \n",
    "   \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file...AMC1300_14150468.txt\n",
      "Processing file...AMC1300_143352425.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a0406675\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2698: DtypeWarning: Columns (0,1,3,4,5,9,12,13,14,19,20,21,22,23,24,25,26,27,29,30,31,32,33,34,35,36,37,38,39,44,45,46,47,48,49,50,51) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os , time\n",
    "import glob\n",
    "import pathlib\n",
    "import re\n",
    "list_of_files_raw_noext=[]\n",
    "\n",
    "PATH_FOR_CLEAN_DATALOG= '//Dtfr-ctpb1h43b/amc1300/Cleanedup/'\n",
    "PATH_FOR_RAW_DATALOG= '//Dtfr-ctpb1h43b/amc1300/'\n",
    "\n",
    "#Get list of files in datalog folder\n",
    "list_of_files_raw = glob.glob(PATH_FOR_RAW_DATALOG+'*.txt')\n",
    "list_of_files_clean = glob.glob(PATH_FOR_CLEAN_DATALOG+'*.csv')\n",
    "latest_file = max(list_of_files_clean, key=os.path.getctime)\n",
    "BASE_FILE_TIME = os.path.getmtime(latest_file)\n",
    "\n",
    "for file in list_of_files_raw:\n",
    "    \n",
    "    re_search_bak = re.search('..bak', file) # search for .bak in filename\n",
    "    file_noext =os.path.basename(file[:-4]) #remove .ext from file name\n",
    "    list_of_files_raw_noext.append(file)\n",
    "    path = pathlib.Path(PATH_FOR_CLEAN_DATALOG+file_noext+'.csv')\n",
    "    re_search = re.search('..Temporary..', file_noext)\n",
    "    if (path.is_file() == False and re_search==None and \n",
    "        re_search_bak==None and os.path.getmtime(file)> BASE_FILE_TIME ):\n",
    "        print(\"Processing file...\"+os.path.basename(file))\n",
    "        #Read the file\n",
    "        df = pd.read_csv(PATH_FOR_RAW_DATALOG+file_noext+'.txt',sep='\\t',delimiter='\\t')\n",
    "        df['index_col'] = df.index\n",
    "        #Rows to be removed (dropped), row 0 and 1\n",
    "        df=df.drop([0,1])\n",
    "        #columns to be removed (dropped)\n",
    "        df=df.drop(['Sweep Version', 'Test Area','Package Type','Product Revision','Test_Parameter',\n",
    "            'Block ID','Channel','Test Type','Station Name','SCM',\n",
    "            'Upper Limit','Lower Limit','Nominal Value','End Time','Execution Duration (ms)',\n",
    "            'Loop Count','Run Mode Name','UserID','Comment'],axis=1)\n",
    "        #df = df.rename(columns={col: col.split('(')[0] for col in df.columns})\n",
    "        type_row=[]    \n",
    "        for column in df:\n",
    "            Column_idx=df.columns.get_loc(column)\n",
    "            for unique_val in df[column].unique():\n",
    "                if(pd.isnull(unique_val)==True):\n",
    "    \n",
    "                  pass\n",
    "                else:\n",
    "                    try:\n",
    "                        float(unique_val)\n",
    "                        isnumber= True\n",
    "                        type_row.append(3.05) #Dummy real for spotfire dtype detection to work\n",
    "                        break \n",
    "                    except:\n",
    "                        Isnumber = False   \n",
    "                        type_row.append('STRING')\n",
    "                        break       \n",
    "        \n",
    "        try:\n",
    "            #Make a data frame with df.columns as index and type_row as column\n",
    "            df2 = pd.Series(type_row, index=[df.columns])\n",
    "            #append df2 transposed to df, gets type_as the last row\n",
    "            df2 = df.append(df2, ignore_index=True)\n",
    "            #swap last row(type row ) and first row\n",
    "            last_row, first_row = df2.iloc[-1].copy(), df2.iloc[0].copy()\n",
    "            df2.iloc[-1],df2.iloc[0] = first_row,last_row\n",
    "            df2.to_csv(PATH_FOR_CLEAN_DATALOG+file_noext+'.csv')\n",
    "            \n",
    "        except:\n",
    "            print(\"Not a valid file \"+file_noext+'.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to fuse temporary .bak and header file.\n",
    "\n",
    "1.Find the temp file pair which are newer than the last clean file\n",
    "2.extract the header and remove NFC\n",
    "3.Add the header as the first row "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to make the script efficient by making a list of \"new\" raw files only  #fail\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Processed file is //Dtfr-ctpb1h43b/amc1300/AMC1300_72726868.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os , time\n",
    "import glob\n",
    "import pathlib\n",
    "import re\n",
    "list_of_files_raw_noext=[]\n",
    "No_of_files_processed=0\n",
    "No_of_files_skipped=0\n",
    "\n",
    "#initialize paths\n",
    "PATH_FOR_CLEAN_DATALOG= '//Dtfr-ctpb1h43b/amc1300/Cleanedup/'\n",
    "PATH_FOR_RAW_DATALOG= '//Dtfr-ctpb1h43b/amc1300/'\n",
    "##BASE_FILE_TIME = 1519948481.7437975\n",
    "\n",
    "\n",
    "def find(name, path):\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        if name in files:\n",
    "            return os.path.join(root, name)\n",
    "\n",
    "#Get list of files in datalog folder\n",
    "list_of_files_raw = glob.glob(PATH_FOR_RAW_DATALOG+'*.txt')\n",
    "list_of_files_clean = glob.glob(PATH_FOR_CLEAN_DATALOG+'*.csv')\n",
    "\n",
    "latest_file_clean = max(list_of_files_clean, key=os.path.getctime)\n",
    "#print ('Latest clean file is ' + os.path.basename(latest_file_clean))\n",
    "latest_clean_file_noext =os.path.basename(os.path.basename(latest_file_clean)[:-4])\n",
    "#print ('Latest clean file noext is ' + latest_clean_file_noext)\n",
    "last_processed_file=find(latest_clean_file_noext+'.txt',PATH_FOR_RAW_DATALOG)\n",
    "print('Last Processed file is '+last_processed_file)\n",
    "list_of_raw_files_unprocessed=[]\n",
    "\n",
    "#BASE_FILE_TIME = os.path.getmtime(latest_file_clean)\n",
    "\n",
    "\n",
    "#list_of_files_raw.sort(key=os.path.getmtime)\n",
    "#list_of_files_raw.reverse()\n",
    "\n",
    "for file in list_of_files_raw:\n",
    "    if (os.path.getmtime(file)>os.path.getmtime(last_processed_file)):\n",
    "        re_search_bak = re.search('..bak', file)\n",
    "        file_noext =os.path.basename(file[:-4]) #remove .ext from file name\n",
    "        re_search = re.search('..Temporary..', file_noext)\n",
    "        if (re_search==None and re_search_bak==None):\n",
    "            list_of_raw_files_unprocessed.append(file)\n",
    "            print('File '+file+' Is added for processing')\n",
    "    else :\n",
    "        break\n",
    "                    \n",
    "            \n",
    "#list_of_raw_files_unprocessed.reverse()            \n",
    "for file in list_of_raw_files_unprocessed:\n",
    "    file_noext =os.path.basename(file[:-4])\n",
    "    print(\"Processing file...\"+file_noext+\".txt\")\n",
    "        #print(\"last modified: %s\" % time.ctime(os.path.getmtime(file)))\n",
    "        #print(\"last modified: %s\" % os.path.getmtime(file))\n",
    "        #Read the file\n",
    "    #df = pd.read_csv(PATH_FOR_RAW_DATALOG+file_noext+'.txt',sep='\\t',delimiter='\\t')  \n",
    "    df = pd.read_csv(file,sep='\\t',delimiter='\\t')\n",
    "    df['index_col'] = df.index\n",
    "        #Rows to be removed (dropped), row 0 and 1\n",
    "    df=df.drop([0,1])\n",
    "      \n",
    "         #columns to be removed (dropped)\n",
    "\n",
    "    df=df.drop(['Sweep Version', 'Test Area','Package Type','Product Revision','Test_Parameter',\n",
    "            'Block ID','Channel','Test Type','Station Name','SCM',\n",
    "            'Upper Limit','Lower Limit','Nominal Value','End Time','Execution Duration (ms)',\n",
    "            'Loop Count','Run Mode Name','UserID','Comment'],axis=1)\n",
    "        #df = df.rename(columns={col: col.split('(')[0] for col in df.columns})\n",
    "        \n",
    "        \n",
    "    type_row=[]    \n",
    "    for column in df:\n",
    "            #print(column)\n",
    "            #print(df[column].unique())\n",
    "            #print('Column index is',df.columns.get_loc(column))\n",
    "            Column_idx=df.columns.get_loc(column)\n",
    "            for unique_val in df[column].unique():\n",
    "                if(pd.isnull(unique_val)==True):\n",
    "                #print(\"this element is NaN\")\n",
    "                  pass\n",
    "                else:\n",
    "                    try:\n",
    "                        float(unique_val)\n",
    "                        isnumber= True\n",
    "                        type_row.append(3.05) #just insert a real num in the first row so that spotfire detects it\n",
    "                        #print(column ,'is a Number')\n",
    "                        break \n",
    "                    except:\n",
    "                        Isnumber = False   \n",
    "                        type_row.append('STRING')\n",
    "                        #print( column,'is a String')\n",
    "                        break       \n",
    "        \n",
    "    try:\n",
    "            #Make a data frame with df.columns as index and type_row as column\n",
    "            df2 = pd.Series(type_row, index=[df.columns])\n",
    "            #append df2 transposed to df, gets type_as the last row\n",
    "            df2 = df.append(df2, ignore_index=True)\n",
    "            #swap last row(type row ) and first row\n",
    "            last_row, first_row = df2.iloc[-1].copy(), df2.iloc[0].copy()\n",
    "            df2.iloc[-1],df2.iloc[0] = first_row,last_row\n",
    "        \n",
    "            df2.to_csv(PATH_FOR_CLEAN_DATALOG+file_noext+'.csv')\n",
    "            \n",
    "    except:\n",
    "            print(\"Not a valid file \"+file_noext+'.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All code below is invalid and is used for debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #columns to be removed (dropped)\n",
    "\n",
    "df=df.drop(['Sweep Version', 'Test Area','Package Type','Product Revision','Test_Parameter',\n",
    "            'Block ID','Channel','Test Type','Start time','Lot','Station Name','SCM',\n",
    "            'Upper Limit','Lower Limit','Nominal Value','End Time','Execution Duration (ms)',\n",
    "            'Loop Count','Run Mode Name','UserID','Comment'],axis=1)\n",
    "        df = df.rename(columns={col: col.split('(')[0] for col in df.columns})      \n",
    "# Type row code\n",
    "        \n",
    "        # write cleaned up dataframe to .csv file of the same name\n",
    "        df2.to_csv('C:/Datafiles/AMC1300/Cleanedup/'+file_noext+'.csv')\n",
    "        print ('Saved as...'+file_noext+'.csv')\n",
    "#         writer = pd.ExcelWriter('C:/Datafiles/AMC1300/Cleanedup/'+file_noext+'.xlsx')\n",
    "#         df2.to_excel(writer,'Sheet1')\n",
    "#         writer.save()\n",
    "#         print ('Saved as...'+file_noext+'.xlsx')\n",
    "        #update processed file counter\n",
    "        No_of_files_processed+=1\n",
    "       \n",
    "    else :\n",
    "        print ('Skipping file...',os.path.basename(file)) \n",
    "        No_of_files_skipped+=1     \n",
    "            \n",
    "            # import pdb; pdb.set_trace()     # Break point for debug\n",
    "print(No_of_files_processed,'files processed')  \n",
    "print (No_of_files_skipped,'files skipped')\n",
    "\n",
    "\n",
    "#for file in list_of_files_processed:\n",
    " #   file =os.path.basename(file[:-4])\n",
    "    #print(file)\n",
    "    #list_of_files_processed_noext.append(file)\n",
    "\n",
    "\n",
    "\n",
    "##for file in list_of_files_raw:\n",
    " ##   file =file[:-4]\n",
    "    #print(file)\n",
    "   ## list_of_files_raw_noext.append(file)\n",
    "    \n",
    "##for file in list_of_files_processed:\n",
    "  ##  file =file[:-4]\n",
    "    #print(file)\n",
    "    ##list_of_files_processed_noext.append(file)    \n",
    "    \n",
    "##print(list_of_files_raw_noext)  \n",
    "#print(list_of_files_processed_noext)   \n",
    "\n",
    "\n",
    "#s = set(list_of_files_processed_noext)\n",
    "#list_of_files_notprocessed_noext = [x for x in list_of_files_raw_noext if x not in s]\n",
    "#print(list_of_files_notprocessed_noext)  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Type Row Code\n",
    "\n",
    "\n",
    "        \n",
    "        #print(df.dtypes)\n",
    "        \n",
    "        type_row=[]    \n",
    "        for column in df:\n",
    "            #print(column)\n",
    "            ##print(df[column].unique())\n",
    "            #print('Column index is',df.columns.get_loc(column))\n",
    "            Column_idx=df.columns.get_loc(column)\n",
    "            for unique_val in df[column].unique():\n",
    "                if(pd.isnull(unique_val)==True):\n",
    "                #print(\"this element is NaN\")\n",
    "                  pass\n",
    "                else:\n",
    "                    try:\n",
    "                        float(unique_val)\n",
    "                        isnumber= True\n",
    "                        type_row.append('FLOAT')\n",
    "                        #print(column ,'is a Number')\n",
    "                        break \n",
    "                    except:\n",
    "                        Isnumber = False   \n",
    "                        type_row.append('STRING')\n",
    "                        #print( column,'is a String')\n",
    "                        break       \n",
    "        \n",
    "        \n",
    "        #Make a data frame with df.columns as index and type_row as column\n",
    "        df2 = pd.Series(type_row, index=[df.columns])\n",
    "        #append df2 transposed to df, gets type_as the last row\n",
    "        df2 = df.append(df2, ignore_index=True)\n",
    "        #swap last row(type row ) and first row\n",
    "        last_row, first_row = df2.iloc[-1].copy(), df2.iloc[0].copy()\n",
    "        df2.iloc[-1],df2.iloc[0] = first_row,last_row\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run BenchDatalog_Cleanup.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run BenchDatalog_Cleanup.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os , time\n",
    "import glob\n",
    "import pathlib\n",
    "import re\n",
    "list_of_files_raw_noext=[]\n",
    "\n",
    "PATH_FOR_CLEAN_DATALOG= '//Dtfr-ctpb1h43b/amc1300/Cleanedup/'\n",
    "PATH_FOR_RAW_DATALOG= '//Dtfr-ctpb1h43b/amc1300/'\n",
    "\n",
    "#Get list of files in datalog folder\n",
    "list_of_files_raw = glob.glob(PATH_FOR_RAW_DATALOG+'*.txt')\n",
    "list_of_files_clean = glob.glob(PATH_FOR_CLEAN_DATALOG+'*.csv')\n",
    "latest_file = max(list_of_files_clean, key=os.path.getctime)\n",
    "BASE_FILE_TIME = os.path.getmtime(latest_file)\n",
    "temp_files=[]\n",
    "\n",
    "\n",
    "list_of_files_raw.sort(key=os.path.getmtime)\n",
    "temp_files=list_of_files_raw[-2:]\n",
    "df = pd.read_csv(temp_files[-2],sep='\\t',delimiter='\\t')\n",
    "\n",
    "\n",
    "for file in list_of_files_raw:\n",
    "    \n",
    "    re_search_bak = re.search('..bak', file) # search for .bak in filename\n",
    "    file_noext =os.path.basename(file[:-4]) #remove .ext from file name\n",
    "    list_of_files_raw_noext.append(file)\n",
    "    path = pathlib.Path(PATH_FOR_CLEAN_DATALOG+file_noext+'.csv')\n",
    "    re_search = re.search('..Temporary..', file_noext)\n",
    "    if (path.is_file() == False and re_search==True\n",
    "         and os.path.getmtime(file)> BASE_FILE_TIME ):\n",
    "        print(\"Processing file...\"+os.path.basename(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Device Descriptor</th>\n",
       "      <th>Sweep Version</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Test Area</th>\n",
       "      <th>Package Type</th>\n",
       "      <th>Product Revision</th>\n",
       "      <th>Test Program Name</th>\n",
       "      <th>Meas_Name</th>\n",
       "      <th>Test_Parameter</th>\n",
       "      <th>Meas_Value</th>\n",
       "      <th>...</th>\n",
       "      <th>SFC - Source</th>\n",
       "      <th>SFC - SCR_ON</th>\n",
       "      <th>NFC - Vpp</th>\n",
       "      <th>NFC - F_Sample</th>\n",
       "      <th>NFC - Bandwidth_INP_Freq(Hz)</th>\n",
       "      <th>NFC - Amp</th>\n",
       "      <th>NFC - CLK</th>\n",
       "      <th>NFC - Fin</th>\n",
       "      <th>NFC - DC_INPUT_FC</th>\n",
       "      <th>NFC - INL_DC_INPUT_MEAS_FC(V)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Device Descriptor, Sweep Version, Product Name, Test Area, Package Type, Product Revision, Test Program Name, Meas_Name, Test_Parameter, Meas_Value, Meas_Unit, P/F Status, Block ID, Channel, Test Type, Start time, Lot, Station Name, UserID, Comment, SCM, Upper Limit, Lower Limit, Nominal Value, End Time, Execution Duration (ms), Loop Count, Run Mode Name, File Path, NFC - DUT, NFC - Temperature(degC), NFC - Device_ID_MSB, NFC - Device_ID_LSB, NFC - RUN, NFC - VDD1(V), NFC - VDD2(V), NFC - Input_Freq(Hz), NFC - Amp(Vp-p), NFC - REP, NFC - SCR_Fs, SFC - Test_Enable, SFC - Sweep_tag, SFC - Source, SFC - SCR_ON, NFC - Vpp, NFC - F_Sample, NFC - Bandwidth_INP_Freq(Hz), NFC - Amp, NFC - CLK, NFC - Fin, NFC - DC_INPUT_FC, NFC - INL_DC_INPUT_MEAS_FC(V)]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 52 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'//Dtfr-ctpb1h43b/amc1300/AMC1300_143352425- Temporary Header File.txt'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_files[-2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
