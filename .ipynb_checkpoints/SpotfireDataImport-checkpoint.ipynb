{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script to Clean up Lab Automation Data before Spotfire Import - \n",
    "\n",
    "Script 1 is for 1 single file (latest file)\n",
    "\n",
    "Script 2 is for all unprocessed files in the folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Datafiles/AMC1300\\AMC1311_161558551- Temporary Data File.txt\n",
      "AMC1311_161558551- Temporary Data File.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import glob\n",
    "import pathlib\n",
    "\n",
    "\n",
    "# * means all if need specific format then *.csv\n",
    "list_of_files = glob.glob('C:/Datafiles/AMC1300/*.txt') \n",
    "latest_file = max(list_of_files, key=os.path.getctime)\n",
    "print (latest_file)\n",
    "File_name=os.path.basename(latest_file)\n",
    "print(File_name)\n",
    "#Remove the .txt extension\n",
    "File_name = File_name[:-4]\n",
    "\n",
    "path = pathlib.Path('C:/Datafiles/AMC1300/Cleanedup/'+File_name+'.csv')\n",
    "re_search = re.search('..Temporary..', File_name)\n",
    "\n",
    "\n",
    " \n",
    "if (path.is_file() == False and re_search == None):\n",
    "#Read the file\n",
    "        print(\"Inside the IF\")\n",
    "        df = pd.read_csv(latest_file,sep='\\t',delimiter='\\t')\n",
    "        df=df.set_index('Meas_Name')\n",
    "        df=df.drop(['RunComment','STRING','TEST_ID'])\n",
    "        df=df.drop(['Sweep Version', 'Test Area','Package Type','Product Revision','Test_Parameter',\n",
    "            'Block ID','Channel','Test Type','Start time','Lot','Station Name','SCM',\n",
    "            'Upper Limit','Lower Limit','Nominal Value','End Time','Execution Duration (ms)',\n",
    "            'Loop Count','Run Mode Name','UserID','Comment'],axis=1)\n",
    "        df.to_csv('C:/Datafiles/AMC1300/Cleanedup/'+File_name+'.csv')\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script 2 - Removes trash columns from data log and inserts type row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file...AMC1300_Data.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a0406675\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2698: DtypeWarning: Columns (0,1,3,4,5,9,12,13,14,19,20,21,22,23,24,25,26,27,29,30,31,32,33,34,35,37,38,39,40,41,42,43,48) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import glob\n",
    "import pathlib\n",
    "import re\n",
    "list_of_files_raw_noext=[]\n",
    "list_of_files_raw = glob.glob('C:/Datafiles/AMC1300/*.txt') \n",
    "No_of_files_processed=0\n",
    "No_of_files_skipped=0\n",
    "PATH_FOR_CLEAN_DATALOG= 'C:/Datafiles/AMC1300/Cleanedup/'\n",
    "PATH_FOR_RAW_DATALOG= 'C:/Datafiles/AMC1300/'\n",
    "\n",
    "for file in list_of_files_raw:\n",
    "    re_search_bak = re.search('..bak', file)\n",
    "    \n",
    "    file_noext =os.path.basename(file[:-4])\n",
    "    list_of_files_raw_noext.append(file)\n",
    "    path = pathlib.Path(PATH_FOR_CLEAN_DATALOG+file_noext+'.csv')\n",
    "    \n",
    "    re_search = re.search('..Temporary..', file_noext)\n",
    "    \n",
    "    if (path.is_file() == False and re_search==None and re_search_bak==None):\n",
    "        print(\"Processing file...\"+os.path.basename(file))\n",
    "         \n",
    "        #Read the file\n",
    "        df = pd.read_csv(PATH_FOR_RAW_DATALOG+file_noext+'.txt',sep='\\t',delimiter='\\t')\n",
    "        \n",
    "        #set Meas_Name as the DF index\n",
    "        df=df.set_index('Device Descriptor')\n",
    "        \n",
    "        #Rows to be removed (dropped)\n",
    "        df=df.drop(['DEV_ID','STRING'])\n",
    "      \n",
    "         #columns to be removed (dropped)\n",
    "\n",
    "        df=df.drop(['Sweep Version', 'Test Area','Package Type','Product Revision','Test_Parameter',\n",
    "            'Block ID','Channel','Test Type','Start time','Lot','Station Name','SCM',\n",
    "            'Upper Limit','Lower Limit','Nominal Value','End Time','Execution Duration (ms)',\n",
    "            'Loop Count','Run Mode Name','UserID','Comment'],axis=1)\n",
    "        df = df.rename(columns={col: col.split('(')[0] for col in df.columns})\n",
    "        \n",
    "        \n",
    "        type_row=[]    \n",
    "        for column in df:\n",
    "            #print(column)\n",
    "            ##print(df[column].unique())\n",
    "            #print('Column index is',df.columns.get_loc(column))\n",
    "            Column_idx=df.columns.get_loc(column)\n",
    "            for unique_val in df[column].unique():\n",
    "                if(pd.isnull(unique_val)==True):\n",
    "                #print(\"this element is NaN\")\n",
    "                  pass\n",
    "                else:\n",
    "                    try:\n",
    "                        float(unique_val)\n",
    "                        isnumber= True\n",
    "                        type_row.append(3.05) #just insert a real num in the first row so that spotfire detects it\n",
    "                        #print(column ,'is a Number')\n",
    "                        break \n",
    "                    except:\n",
    "                        Isnumber = False   \n",
    "                        type_row.append('STRING')\n",
    "                        #print( column,'is a String')\n",
    "                        break       \n",
    "        \n",
    "        \n",
    "        #Make a data frame with df.columns as index and type_row as column\n",
    "        df2 = pd.Series(type_row, index=[df.columns])\n",
    "        #append df2 transposed to df, gets type_as the last row\n",
    "        df2 = df.append(df2, ignore_index=True)\n",
    "        #swap last row(type row ) and first row\n",
    "        last_row, first_row = df2.iloc[-1].copy(), df2.iloc[0].copy()\n",
    "        df2.iloc[-1],df2.iloc[0] = first_row,last_row\n",
    "        \n",
    "        df2.to_csv(PATH_FOR_CLEAN_DATALOG+file_noext+'.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All code below is invalid and is used for debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #columns to be removed (dropped)\n",
    "\n",
    "df=df.drop(['Sweep Version', 'Test Area','Package Type','Product Revision','Test_Parameter',\n",
    "            'Block ID','Channel','Test Type','Start time','Lot','Station Name','SCM',\n",
    "            'Upper Limit','Lower Limit','Nominal Value','End Time','Execution Duration (ms)',\n",
    "            'Loop Count','Run Mode Name','UserID','Comment'],axis=1)\n",
    "        df = df.rename(columns={col: col.split('(')[0] for col in df.columns})      \n",
    "# Type row code\n",
    "        \n",
    "        # write cleaned up dataframe to .csv file of the same name\n",
    "        df2.to_csv('C:/Datafiles/AMC1300/Cleanedup/'+file_noext+'.csv')\n",
    "        print ('Saved as...'+file_noext+'.csv')\n",
    "#         writer = pd.ExcelWriter('C:/Datafiles/AMC1300/Cleanedup/'+file_noext+'.xlsx')\n",
    "#         df2.to_excel(writer,'Sheet1')\n",
    "#         writer.save()\n",
    "#         print ('Saved as...'+file_noext+'.xlsx')\n",
    "        #update processed file counter\n",
    "        No_of_files_processed+=1\n",
    "       \n",
    "    else :\n",
    "        print ('Skipping file...',os.path.basename(file)) \n",
    "        No_of_files_skipped+=1     \n",
    "            \n",
    "            # import pdb; pdb.set_trace()     # Break point for debug\n",
    "print(No_of_files_processed,'files processed')  \n",
    "print (No_of_files_skipped,'files skipped')\n",
    "\n",
    "\n",
    "#for file in list_of_files_processed:\n",
    " #   file =os.path.basename(file[:-4])\n",
    "    #print(file)\n",
    "    #list_of_files_processed_noext.append(file)\n",
    "\n",
    "\n",
    "\n",
    "##for file in list_of_files_raw:\n",
    " ##   file =file[:-4]\n",
    "    #print(file)\n",
    "   ## list_of_files_raw_noext.append(file)\n",
    "    \n",
    "##for file in list_of_files_processed:\n",
    "  ##  file =file[:-4]\n",
    "    #print(file)\n",
    "    ##list_of_files_processed_noext.append(file)    \n",
    "    \n",
    "##print(list_of_files_raw_noext)  \n",
    "#print(list_of_files_processed_noext)   \n",
    "\n",
    "\n",
    "#s = set(list_of_files_processed_noext)\n",
    "#list_of_files_notprocessed_noext = [x for x in list_of_files_raw_noext if x not in s]\n",
    "#print(list_of_files_notprocessed_noext)  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Type Row Code\n",
    "\n",
    "\n",
    "        \n",
    "        #print(df.dtypes)\n",
    "        \n",
    "        type_row=[]    \n",
    "        for column in df:\n",
    "            #print(column)\n",
    "            ##print(df[column].unique())\n",
    "            #print('Column index is',df.columns.get_loc(column))\n",
    "            Column_idx=df.columns.get_loc(column)\n",
    "            for unique_val in df[column].unique():\n",
    "                if(pd.isnull(unique_val)==True):\n",
    "                #print(\"this element is NaN\")\n",
    "                  pass\n",
    "                else:\n",
    "                    try:\n",
    "                        float(unique_val)\n",
    "                        isnumber= True\n",
    "                        type_row.append('FLOAT')\n",
    "                        #print(column ,'is a Number')\n",
    "                        break \n",
    "                    except:\n",
    "                        Isnumber = False   \n",
    "                        type_row.append('STRING')\n",
    "                        #print( column,'is a String')\n",
    "                        break       \n",
    "        \n",
    "        \n",
    "        #Make a data frame with df.columns as index and type_row as column\n",
    "        df2 = pd.Series(type_row, index=[df.columns])\n",
    "        #append df2 transposed to df, gets type_as the last row\n",
    "        df2 = df.append(df2, ignore_index=True)\n",
    "        #swap last row(type row ) and first row\n",
    "        last_row, first_row = df2.iloc[-1].copy(), df2.iloc[0].copy()\n",
    "        df2.iloc[-1],df2.iloc[0] = first_row,last_row\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
